
이번 데모데이 요구사항은 스레드 풀 관련 설정값인 threads max, max connections, accept count를 적절하게 설정하는 것, 서비스에서 사용하는 모든 조회 쿼리와 테이블에 인덱스를 설정하는 것이었습니다. 

두 설정 작업 모두 API 서버 작업 처리 성능에 영향을 크게 미치는 것들이었기에 어떤 작업을 먼저 수행해줄 지 고민이 되었습니다. 팀 내 논의 결과 일단 DB 조회 쿼리에서 인덱스 지정으로 인한 최적화가 선행된 상태에서 스레드 풀 설정값 튜닝을 진행하는 것이 좀 더 안정적이고 의미있는 작업이 될 것이라 판단했기에 해당 순서대로 진행하였습니다.


# 백엔드 기능 구현

### 스터디 참여 인원 동시 진행 기능 추가 구현

- SSE 기술 검토 및 학습 진행
	- 프론트와 함께 Server Side Event 방식으로 통신이 어떻게 이뤄지는지 검토
		- 프론트 단에서 어떤 방식으로 이벤트를 받아야 하는지
		- 백엔드에서는 어떻게 이벤트를 생성해서 넘겨야 하는지.
	- 현재는 인메모리 방식으로 SseEmitter 관리 방식으로 시연코드 적용에는 성공
	- 이후 프로덕션 로직에 적용할 예정
- 적용 시 로깅 필터작업으로 인한 SSE 연결 문제 트러블 슈팅
- DB 및 젠킨스 예약 배포 작업
	- 중단예약배포 => 서비스다운 타임 짧게 새벽에 가져갈 수 있는지
	- nginx 라우팅에서 crontab 활용해서 점검 페이지 띄웠다가 배포 완료 후 다시 정상 라우팅 처리하도록 작업 진행
### 로그인 시 외부 API 호출 로직 트랜잭션 분리




# 인덱스 설정

현재 하루스터디 서버에서 수행되는 조회 쿼리 목록들은 다음과 같습니다.

### participantCode 테이블 (전체 미적용)
- select * from participant_code where code = ?
	- code 컬럼 (미적용)

- select * from participant_code where study_id = ?
	- study_Id 컬럼 (미적용)
=> 조회만큼 생성 삭제 로직이 빈번하기 때문에 인덱스 적용하기에 부적합하다 판단 + 향후 서버 scale out 시 별도로 관리해줘야 할 필요성 및 SSE 기능 추가 구현 예정으로 인해 현상 유지

### study 테이블
- pk 조회 외 별도 없음
- select * from pomodoro_study;

### pomodoro_progress 테이블
- select * from pomodoro_progress where pomodoro_study_id=? and member_id=?
	- memberId, studyId, nickname 컬럼 => 복합키 적용
=> 실질적으로 필요한 데이터가 nickname 하나밖에 없어 이후 Dto projection을 사용하여 커버링 인덱스 적용하여 추가적인 성능 개선 예정

- select * from pomodoro_progress join member on member.id = pomodoro_progress.member_id where pomodoro_study_id = ?
	- pomodoro_study_id 컬럼 => 단일 인덱스 적용

- select * from pomodoro_progress where member_id = ?
	- memberId, studyId, nickname 컬럼 => 적용해둔 복합키 재활용

- select * from pomodoro_progress where study_id = ?
	- pomodoro_study_id 컬럼 => 단일 인덱스 적용

### content 테이블
- select * from pomodoro_content where pomodoro_progress_id=?
	- pomodoro_progress_id 컬럼 => 인덱스 적용

### member 테이블
- select * from member where email = ?
	- email 컬럼 => 인덱스 적용


### refreshToken 테이블
	- uuid 컬럼 => 인덱스 적용
=> uuid는 인증 관련 토큰 갱신 시 지속적으로 값이 변경되어야 하므로 PK로는 부적절함. 하지만 로그인한 사용자의 모든 요청마다 refreshToken 조회를 수행하므로 컬럼 값 변경에 따른 오버헤드보다 인덱스 적용으로 인한 조회 성능 개선의 이점이 더 크다고 판단하여 적용

- select * from refresh_token where member_id = ?
	- member_id 컬럼 => 인덱스 적용



실제로 인덱스를 적용한 뒤 유의미한 조회 성능 개선이 이뤄졌는지 확인하기 위해 부하테스트 도구를 사용하여 인덱스 적용 전 후 성능 측정을 진행하였습니다. 

(API에서 아직 수정되지 않은 이름 어떻게 통일할지 결정하기 progress/ participant)
시간 관계 상 사용자의 스터디 진행상태를 조회하는 API(/api/studies/100012/progress?memberId=100012)에서 수행되는 스터디 진행도 테이블 조회 쿼리 성능 테스트만 짚고 넘어가도록 하겠습니다. 

![[indexBefore.png]]

인덱스 걸기 전 사진 후 사진 인증

실제 성능 테스트를 위해 10만개의 더미데이터를 생성하여 진행.
이후 로커스트 테스트 진행 시 성능이 대략 8배에 가까운 성능 개선이 이뤄졌음을 확인할 수 있었습니다.

인덱스 적용 이후 로커스트 테스트 결과 이미지


# 스레드 풀 튜닝

조회 쿼리들에 대한 인덱스 설정이 완료된 후 스레드 풀 튜닝을 진행하기 위해 튜닝 대상 값들을 어떤 방식으로 테스트를 진행하며 튜닝할지를 먼저 논의했습니다. 스레드 풀 설정 값들을 튜닝하기 위해서는 기본 설정 값에서 현재 저희 서버의 API가 어느 정도로 요청들을 처리해낼 수 있는지를 먼저 확인해야 한다고 판단했습니다. 이를 위해 인덱스를 설정할 때처럼 전후 성능을 테스트하기 위해 사용했던 부하테스트 도구를 통해 API의 현재 성능을 측정한 뒤에 이를 기준으로 최적의 튜닝 값을 찾고자 했습니다.


/studies/{studyId}/contents?progressId=100001&cycle=1
다음의 API는 하루스터디 서비스에서 스터디를 진행한 사용자가 작성한 계획, 회고 등의 컨텐츠를 필터링해서 조회하는 작업을 수행합니다. 해당 API에 대한 부하테스트를 진행하는 도중 이상한 점을 발견할 수 있었습니다.


|api/|ThreadMax|accept-count|max-connection|rps|
|---|---|---|---|---|
|/studies/{studyId}/contents?progressId=100001&cycle=1|10|100|8192|33||
|/studies/{studyId}/contents?progressId=100001&cycle=1|50|100|8192|33||
|/studies/{studyId}/contents?progressId=100001&cycle=1|100|100|8192|33||
|/studies/{studyId}/contents?progressId=100001&cycle=1|200|100|8192|33||

다음 표에 나와있는 것과 같이 기본 스레드 풀 튜닝 값으로 진행해서 얻어낸 성능이 threadMax 값을 변경하며 테스트를 진행해도 변하지 않는 현상을 확인할 수 있었습니다. 원인이 무엇인지 파악하기 위해 그라파나를 모니터링하던 중 DB Hikari CP 커넥션에 대한 메트릭을 확인하게 되었습니다.

![[thread100connectionpoolPending 1.png]]

 
컨텐츠 조회 API에 대한 부하테스트를 진행한 뒤 그라파나에 수집되는 여러 메트릭을 확인하던 도중 HikariCP 커넥션의 상태가 상기 이미지와 같았습니다. 확인해본 결과 Active된 HkariCP 커넥션 수가 10개고 pending되어 지연되고 있는 커넥션이 존재하고 있다는 사실을 그라파나 그래프를 통해 알 수 있었습니다. 저희 팀에서는 해당 API가 DB 커넥션 개수 설정으로 인해 RPS가 유의미하게 변화하지 않았을 수 있었겠다는 분석을 할 수 있었고 DB Hikari CP 커넥션 개수를 200까지 늘려서 다시 테스트 해보기로 결정했습니다. 

하지만 저희의 예상과는 다르게 DB 커넥션 개수를 200으로 설정한 뒤에도 컨텐츠 조회 API의 RPS는 DB 커넥션 설정 값을 변경하기 전과 동일하게 측정되었습니다. 이 결과에 대해 저희 팀은 스레드 풀이나 DB 커넥션 관련 설정 값 튜닝으로 성능 개선을 해야하는 문제가 아니라고 판단했습니다. 이후 서비스 코드를 재검토해본 결과 API 호출 시 수행하는 로직 및 실행 쿼리를 개선해야 하는 문제라고 결론을 내렸습니다. 

데모데이 이후 이러한 API들에 대해서는 로직 최적화 과정을 수행한 뒤 파라미터 튜닝을 다시 수행할 계획입니다. 

api/me 테스트 진행한 거 제시하면서 유의미한 결과가 나오기도 했었다를 살짝 언급해도 좋을 듯

다른 API들에 대해서도 부하테스트를 진행하며 스레드 풀 튜닝을 위한 근거를 마련하고자 했었으나 저희가 설계한 튜닝 과정에서 다음과 같은 문제들이 있었음을 뒤늦게 알아차리게 되었습니다.

- 서비스의 실제 사용 시나리오를 생각하지 않고 특정 API에 대해서만 부하 테스트를 진행하며 튜닝을 진행한 점
- DB connection pool 관련 설정 값의 영향, 서비스 로직 자체의 성능 개선사항, 스터디 동시 진행 기능 업데이트 등으로 인한 변수 발생 가능성이 존재할 수 있다는 점
- 부하테스트 도구와 방법에 대한 학습 부족으로 인해 올바른 테스트 결과를 도출해내지 못했다는 점

시간적 한계로 인해 문제점들을 해결하고 만족할만한 수준의 튜닝을 진행하기 어려웠기에 일단은 기존 스레드 풀 설정값을 유지하고 이후 문제점들을 해결한 뒤 튜닝을 진행하는 방향으로 결정했습니다.





결론 : 서비스 사용 시나리오를 생각해보지 않고 특정 API에 대해서만 부하 테스트를 진행하며 튜닝을 진행하려고 했던 점. 고려하지 못한 변수가 중간에 너무 많이 발견되었고, 부하테스트 툴이 어떤 방식으로 동작하는지 정확하게 파악하지 못한 점. 




---





(acceptCount, maxConnections 값은 고정하고 threadMax만 변경하며 튜닝을 진행하기로 결정한 이유 정리)








### API 선정 기준
DB 조회 쿼리가 수행되는 API들 중에서 한 API 작업 내에 몇 번의 조회 요청을 하는가를 기준으로 분류했습니다. (그 중 사용자 시나리오 상에서 상대적으로 중요하다고 판단되는 API를 선정하게 되었습니다.)

(API 별 TPS 설정 값 기준 잡기)
(튜닝 대상 API 명시)

threadMax = {10, 50, 100, 200} 로 후보군을 설정하고 튜닝 대상 API들에 대해 부하 테스트를 진행하며 TPS를 측정했습니다.


측정을 하다보니 스레드풀 관련 튜닝 값을 변경해도 TPS에 유의미한 변화를 주지 못하는 API들이 발견되었습니다. 

/studies/{studyId}/contents?progressId=100001&cycle=1
해당 API는 스터디 참여자의 특정 사이클에 기록된 스터디 계획과 회고 정보를 조회하는 요청을 처리합니다. 해당 API에 대해 threadMax 수치를 변경하며 부하 테스트를 진행해도 RPS가 동일한 수치를 기록함을 다음과 같이 알 수 있었습니다. 

|api/|ThreadMax|accept-count|max-connection|rps|response time(95th, sec)|
|---|---|---|---|---|---|
|/studies/{studyId}/contents?progressId=x,cycle=1|50|100|8192|33||
|/studies/{studyId}/contents?progressId=x,cycle=1|100|100|8192|33||

(컨텐츠 조회 API 부하테스트 결과 이미지 필요함)


![[thread100connectionpoolPending.png]]

컨텐츠 조회 API에 대한 부하테스트를 진행한 뒤 그라파나에 수집되는 여러 메트릭을 확인하던 도중 HikariCP 커넥션의 상태가 상기 이미지와 같았습니다. 확인해본 결과 Active된 HkariCP 커넥션 수가 10개고 pending되어 지연되고 있는 커넥션이 존재하고 있다는 사실을 그라파나 그래프를 통해 알 수 있었습니다. 저희 팀에서는 해당 API가 DB 커넥션 개수 설정으로 인해 RPS가 유의미하게 변화하지 않았을 수 있었겠다는 분석을 할 수 있었고 DB Hikari CP 커넥션 개수를 200까지 늘려서 다시 테스트 해보기로 결정했습니다. 

하지만 저희의 예상과는 다르게 DB 커넥션 개수를 200으로 설정한 뒤에도 컨텐츠 조회 API의 RPS는 DB 커넥션 설정 값을 변경하기 전과 동일하게 측정되었습니다. 이 결과에 대해 저희 팀은 스레드 풀이나 DB 커넥션 관련 설정 값 튜닝으로 성능 개선을 해야하는 문제가 아니라고 판단했습니다. 이후 서비스 코드를 재검토해본 결과 API 호출 시 수행하는 로직 및 실행 쿼리를 개선해야 하는 문제라고 결론을 내렸습니다. 

데모데이 이후 이러한 API들에 대해서는 로직 최적화 과정을 수행한 뒤 파라미터 튜닝을 다시 적용할 계획입니다. 



호출 시 처리해야 하는 서비스 로직은 비슷한데 DB 조회 쿼리를 수행하는 횟수를 달리하는 API들을 각각 선정하여 부하테스트 진행




결론 : 서비스 사용 시나리오를 생각해보지 않고 특정 API에 대해서만 부하 테스트를 진행하며 튜닝을 진행하려고 했던 점. 고려하지 못한 변수가 중간에 너무 많이 발견되었고, 부하테스트 툴이 어떤 방식으로 동작하는지 정확하게 파악하지 못한 점. 


---
왜 수립한 홍보계획을 진행하지 못했나?
- 서비스 주 타겟층은 데스크탑 웹 서비스 이용자였으나 홍보를 통해 접하는 매체가 모바일인 경우가 대부분일 것이기 때문에 반응형 UI를 적용하고 진행하는 것이 더 나은 방향이라 판단했다.
- 반응형을 빠르게 도입하려고 했는데 막상 해보니 소요되는 시간도 많았고, 다른 부가적인 변수 태스크들이 많이 발생하여 제대로된 일정 추산이 되지 않았다.
- 6차 데모데이 시작 직후 첫 주 안에 반응형 UI 적용을 완료하고 홍보 진행 예정